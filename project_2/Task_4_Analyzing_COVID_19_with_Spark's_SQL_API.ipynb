{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jewbe22/eecs4415_Big_data/blob/main/project_2/Task_4_Analyzing_COVID_19_with_Spark's_SQL_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# EECS 4415 - Task 4\n",
        "## Analyzing COVID-19 with Spark's SQL API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's set up Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "collapsed": true
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUjUvXe3Sjk"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the files we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRElWs_x2mGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3b2782-2ebd-42ad-f54d-7c16e84dad8f"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "source": [
        "id='1YT7ttUAafCjbVdm6obeHp1TWAK0rEtoR'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('time_series_covid19_confirmed_global.csv')\n",
        "\n",
        "id='1YxEA5UQ2EFJ_9oLssM__Gs1ncVNufGNA'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('time_series_covid19_deaths_global.csv')\n",
        "\n",
        "id='1CNxszuZTeIw-5cF5yrzKMZdb1qV0hSoy'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('time_series_covid19_recovered_global.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "Next, we import some of the common libraries needed for our task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's initialize the Spark context. (If there is an errror based on the previous sessions, go to Runtime-> Restart session.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3sAVeK1EDZ"
      },
      "source": [
        "# create the session\n",
        "\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, we will be analyzing the time series data of the Coronavirus COVID-19 Global Cases, collected by Johns Hopkins CSSE.\n",
        "\n",
        "Here you can check a dashboard based on this dataset: [https://www.arcgis.com/apps/opsdashboard/index.html?fbclid=IwAR2hQKsEZ3D38wVtXGryUhP9CG0Z6MYbUM_boPEaV8FBe71wUvDPc65ZG78#/bda7594740fd40299423467b48e9ecf6](https://www.arcgis.com/apps/opsdashboard/index.html?fbclid=IwAR2hQKsEZ3D38wVtXGryUhP9CG0Z6MYbUM_boPEaV8FBe71wUvDPc65ZG78#/bda7594740fd40299423467b48e9ecf6)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   ```confirmed```: dataframe containing the cumulative number of confirmed COVID-19 cases, divided by geographical area\n",
        "*   ```deaths```: dataframe containing the cumulative number of deaths due to COVID-19, divided by geographical area\n",
        "*   ```recovered```: dataframe containing the cumulative number of recoevered patients, divided by geographical area\n",
        "\n",
        "The data sets contain data entries for each day, representing the cumulative totals as of that day.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUSeIQlNqv6J"
      },
      "source": [
        "confirmed = spark.read.csv('time_series_covid19_confirmed_global.csv', header=True)\n",
        "deaths = spark.read.csv('time_series_covid19_deaths_global.csv', header=True)\n",
        "recovered = spark.read.csv('time_series_covid19_recovered_global.csv', header=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvyFsE-fLXpg",
        "collapsed": true
      },
      "source": [
        "confirmed.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confirmed.show()"
      ],
      "metadata": {
        "id": "r0O-FogNxBq6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV45mAMfrmxA"
      },
      "source": [
        "### Your Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wYiCEv_zhVf"
      },
      "source": [
        "Consider the entries for May 1, 2021, in the timeseries, and compute:\n",
        "\n",
        "*   number of confirmed COVID-19 cases across the globe\n",
        "*   number of deaths due to COVID-19 (across the globe)\n",
        "*   number of recovered patients across the globe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Hoy-9Xzf8r",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25634817-8a13-47e1-d410-6fbacb59afbd"
      },
      "source": [
        "\n",
        "''' 6 lines of code in total expected. '''\n",
        "\n",
        "# YOUR CODE HERE\n",
        "confirmed_5_1_21 = confirmed.select(sum(\"5/1/21\").alias(\"# of confirmed\"))\n",
        "deaths_5_1_21 = deaths.select(sum(\"5/1/21\").alias(\"# of deaths\"))\n",
        "recovered_5_1_21 = recovered.select(sum(\"5/1/21\").alias(\"# of recovered\"))\n",
        "confirmed_5_1_21.show()\n",
        "deaths_5_1_21.show()\n",
        "recovered_5_1_21.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|# of confirmed|\n",
            "+--------------+\n",
            "|  1.52196159E8|\n",
            "+--------------+\n",
            "\n",
            "+-----------+\n",
            "|# of deaths|\n",
            "+-----------+\n",
            "|  3192930.0|\n",
            "+-----------+\n",
            "\n",
            "+--------------+\n",
            "|# of recovered|\n",
            "+--------------+\n",
            "|   8.8919401E7|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yahkAHoS0HuU"
      },
      "source": [
        "Consider the data points for March 1, 2020, and March 1, 2021, and filter out the geographical locations where less than 50 cases have been confirmed. For the areas still taken into consideration after the filtering step, compute the ratio between number of deaths and number of confirmed cases. Show top 20 rows.\n",
        "\n",
        "Hint: You do not need to sum over the country(combine Province/State having the same Country/Region). In other words, the column Province/State should exist in the final dataframe for this question.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FwzsH4l1VCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e0cf3c-7e30-4f33-d1d2-91c83b966a8d"
      },
      "source": [
        "''' 16-20 lines of code in total expected but can differ based on your style. '''\n",
        "\n",
        "# YOUR CODE HERE\n",
        "confirmed_filtered = confirmed.select(\"Province/State\", \"Country/Region\",col(\"3/1/20\").alias(\"confirmed_3/1/20\"),\\\n",
        "                                      col(\"3/1/21\").alias(\"confirmed_3/1/21\"))\\\n",
        "                                      .where((confirmed[\"3/1/20\"] >= 50) & (confirmed[\"3/1/21\"] >= 50))\n",
        "\n",
        "deaths_filtered = deaths.select(\"Province/State\", \"Country/Region\",col(\"3/1/20\").alias(\"deaths_3/1/20\"), col(\"3/1/21\").alias(\"deaths_3/1/21\"))\n",
        "\n",
        "combined = confirmed_filtered.join(deaths_filtered,\\\n",
        "                                   (confirmed_filtered[\"Province/State\"] == deaths_filtered[\"Province/State\"])\\\n",
        "                                   & (confirmed_filtered[\"Country/Region\"] == deaths_filtered[\"Country/Region\"]), \"inner\")\n",
        "\n",
        "ratio = combined.select((col(\"deaths_3/1/20\")/col(\"confirmed_3/1/20\")).alias(\"ratio_3/1/20\"),\\\n",
        "                          (col(\"deaths_3/1/21\")/col(\"confirmed_3/1/21\")).alias(\"ratio_3/1/21\"))\n",
        "\n",
        "ratio.show(20)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|        ratio_3/1/20|        ratio_3/1/21|\n",
            "+--------------------+--------------------+\n",
            "|0.006060606060606061|0.006036217303822937|\n",
            "| 0.01937046004842615|0.008579599618684462|\n",
            "|0.010416666666666666| 0.01015228426395939|\n",
            "|0.003378378378378...|0.001814882032667...|\n",
            "| 0.02197802197802198|  0.0106951871657754|\n",
            "|0.005189028910303929|0.003611738148984...|\n",
            "|0.007936507936507936| 0.00749063670411985|\n",
            "|  0.0136986301369863|0.013605442176870748|\n",
            "| 0.02976190476190476| 0.03508771929824561|\n",
            "|0.018867924528301886|0.005315110098709187|\n",
            "|0.027083333333333334|0.008074534161490683|\n",
            "| 0.01729559748427673| 0.01685823754789272|\n",
            "|0.020833333333333332|0.018150467374534893|\n",
            "|  0.0412662352220246| 0.06620592507813532|\n",
            "|0.003929273084479371|0.003861003861003861|\n",
            "|                 0.0|0.002724795640326...|\n",
            "|                 0.0|                 0.0|\n",
            "|0.001069518716577...|0.001069518716577...|\n",
            "|0.010752688172043012|0.005235602094240838|\n",
            "| 0.00819672131147541|0.004926108374384...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLBtZyFqPKkI"
      },
      "source": [
        "Consider the data points for March 1, 2021, and May 1, 2021, in the timeseries, and filter out the geographical locations where less than 50 deaths have been confirmed. Show the top 20 rows for May 1, 2021 (as March 1, 2021 has already been shown before).\n",
        "\n",
        "For the areas still taken into consideration after the filtering step, compute **the percent increase in cumulative deaths** between the two dates. Show top 20 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUWisUyMPI9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a24254-fb6e-484a-9f72-4fee3cb4bc0e"
      },
      "source": [
        "''' 5-12 lines of code in total expected but can differ based on your style.'''\n",
        "\n",
        "# YOUR CODE HERE\n",
        "deaths_increment = deaths.select(\"Province/State\",\"Country/Region\",\"3/1/21\", \"5/1/21\")\\\n",
        ".where((deaths[\"3/1/21\"] >= 50) & (deaths[\"5/1/21\"] >= 50))\n",
        "\n",
        "deaths_increment.select(\"Province/State\",\"Country/Region\", \"5/1/21\").show(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+------+\n",
            "| Province/State|      Country/Region|5/1/21|\n",
            "+---------------+--------------------+------+\n",
            "|           NULL|         Afghanistan|  2631|\n",
            "|           NULL|             Albania|  2396|\n",
            "|           NULL|             Algeria|  3261|\n",
            "|           NULL|             Andorra|   125|\n",
            "|           NULL|              Angola|   600|\n",
            "|           NULL|           Argentina| 64096|\n",
            "|           NULL|             Armenia|  4128|\n",
            "|New South Wales|           Australia|    54|\n",
            "|       Victoria|           Australia|   820|\n",
            "|           NULL|             Austria| 10233|\n",
            "|           NULL|          Azerbaijan|  4538|\n",
            "|           NULL|             Bahamas|   199|\n",
            "|           NULL|             Bahrain|   648|\n",
            "|           NULL|          Bangladesh| 11510|\n",
            "|           NULL|             Belarus|  2552|\n",
            "|           NULL|             Belgium| 24258|\n",
            "|           NULL|              Belize|   323|\n",
            "|           NULL|               Benin|    99|\n",
            "|           NULL|             Bolivia| 13009|\n",
            "|           NULL|Bosnia and Herzeg...|  8551|\n",
            "+---------------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deaths_increment.select(((col(\"5/1/21\")-col(\"3/1/21\"))/col(\"3/1/21\") * 100).alias(\"percentage of increase\")).show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbXe2Nf3qElo",
        "outputId": "39a2010e-7608-47b0-cf7e-f6372c83653a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+\n",
            "|percentage of increase|\n",
            "+----------------------+\n",
            "|    7.6513911620294595|\n",
            "|    31.938325991189426|\n",
            "|     9.173083361232006|\n",
            "|    13.636363636363635|\n",
            "|     18.11023622047244|\n",
            "|    23.079286441231254|\n",
            "|    29.201877934272304|\n",
            "|                   0.0|\n",
            "|                   0.0|\n",
            "|    19.349195241427573|\n",
            "|     40.80049643189575|\n",
            "|      11.1731843575419|\n",
            "|     43.36283185840708|\n",
            "|     36.76330798479088|\n",
            "|     28.56423173803526|\n",
            "|     9.734913598118158|\n",
            "|    2.5396825396825395|\n",
            "|     41.42857142857143|\n",
            "|    11.512086404937424|\n",
            "|     68.62551764937882|\n",
            "+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a paragraph of conclusions below summarizing your insights."
      ],
      "metadata": {
        "id": "FeR4N0o0ztq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The query object alone does not hold any subset of dataframe resides in the disk. Only when data retrieval commnad is issued, such as collect() or show(), the dataset is filtered by the query and brought in to the memory using SQL optimazation schme and more. So, there is little or no  overhead of bring the whole dataset first into the memroy and filter it as long as our query filters fair enough amount of rows in the dataset. Although, if our query filters out little or no rows/columns, it would be the same as brining the whole dataset into the memory anyway.    "
      ],
      "metadata": {
        "id": "mmne7Rlj0pHO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrXJyVNP2AI"
      },
      "source": [
        "Once you have working code for each cell above, **head over to eClass, and submit your solution for this Colab**!"
      ]
    }
  ]
}